---
title: "H1_energyact emb2"
output:
  pdf_document: default
  html_document: default
date: "Sys.Date()"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#Install and load necessary packages
packages <- c("devtools","here","dplyr","tidyverse","readxl","writexl","hunspell","text2vec","car","broom","lme4")
for (package in packages) {
  if (!requireNamespace(package, quietly = TRUE)) {
    install.packages(package)
  }
}
lapply(packages,library, character.only=T)
```

```{r}
#Install and load embedR
if (!requireNamespace("embedR", quietly = TRUE)) {
    # If not installed, install it using devtools
    devtools::install_github("dwulff/embedR")
}

library("embedR")
```

```{r}
#read in final dataset
energyact_fin <- read_xlsx(here::here("data","energyact_final.xlsx"))

#load embeddings as R object
embedding <- readRDS(here::here("data","embedding.rds"))
```

```{r,eval=F, echo=F}
#embed chatGPT list
#economy words
#embedR::er_set_tokens("cohere" = "x","huggingface"="x","openai" = "x")

#embedding_econ = er_embed(c("kosten","teuer","preis","arbeit","investition","wirtschaft","finanzierung","budget","ausgaben","steuern","subvention","gewinn","verlust","rendite","sparen","wettbewerb","verschuldung","einkommen","umsatz","markt"),api="cohere",model="embed-multilingual-v3.0")

#environmental prot words
#embedding_env = er_embed(c("umweltschutz","klimaschutz","dringend","notwendig","nachhaltigkeit","erneuerbar","ökologie","biodiversität","artenschutz","ressourcenschonung","emission","klimawandel","ökosystem","umweltbewusstsein","grüne energie","verschmutzung","zeitdruck","landschaftsschutz","naturschutz","tierschutz"),api="cohere",model="embed-multilingual-v3.0")
```

```{r,eval=F, echo=F}
#save embeddings as R object
#saveRDS(embedding_econ, here::here("data","embedding_econ.rds"))

#saveRDS(embedding_env, here::here("data","embedding_env.rds"))

```

```{r}
calculate_max_similarity <- function(embedding_study, embedding_list) {
  # Calculate cosine similarity
  similarity_matrix <- sim2(embedding_study, embedding_list, method = "cosine")
  # Get the maximum similarity score for each word
  max_similarity <- apply(similarity_matrix, 1, max)
  return(max_similarity)
}
```

```{r}
#Load embeddings
embedding_econ <- readRDS(here::here("data","embedding_econ.rds"))

embedding_env <- readRDS(here::here("data","embedding_env.rds"))
# Creating a dataframe from the study embedding matrix
H1_df <- as.data.frame(embedding)

# Save the rownames as the first column in H1_df
H1_df$word <- rownames(H1_df)

# Reset the rownames of H1_df
rownames(H1_df) <- NULL



# Calculate max similarities
H1_df$max_similarity_econ <- calculate_max_similarity(embedding, embedding_econ)
H1_df$max_similarity_env <- calculate_max_similarity(embedding, embedding_env)
```

```{r}
#add similarity columns to energyact_fin
# Get the names of the last two columns
last_two_columns <- names(H1_df)[(ncol(H1_df)-1):ncol(H1_df)]

# Add the last two columns from H1_df to energyact_fin
energyact_fin[last_two_columns] <- H1_df[last_two_columns]
```

```{r}
#Visualize similarity distribution to extract threshold, first for economy words
#First create ordered df
energyact_fin_ordered_econ <- energyact_fin[order(-energyact_fin$max_similarity_econ), ]

#Calculate median similarity
median_similarity_econ <- median(energyact_fin_ordered_econ$max_similarity_econ, na.rm = TRUE)

# Create the plot
plot_sim_econ <- ggplot(energyact_fin_ordered_econ, aes(x = reorder(row.names(energyact_fin_ordered_econ), -max_similarity_econ), y = max_similarity_econ)) +
  geom_hline(yintercept = median_similarity_econ, linetype = "dashed", color = "blue") +
  geom_point() +
  #theme(axis.text.x = element_blank()) +  # Hide x-axis text for legibility
  labs(x = "Words", y = "Max Similarity to Economy", title = "Similarity Scores for Economy Category") +
  scale_y_continuous(breaks = seq(0, 1, by = 0.05)) +  # Set y-axis breaks
  theme_classic()

plot_sim_econ
#threshold 0.75
```

```{r}
# Create ordered dataframe based on max_similarity_env
energyact_fin_ordered_env <- energyact_fin[order(-energyact_fin$max_similarity_env), ]

# Calculate median similarity for environmental protection
median_similarity_env <- median(energyact_fin_ordered_env$max_similarity_env, na.rm = TRUE)

# Create the plot for environmental protection similarity
plot_sim_env <- ggplot(energyact_fin_ordered_env, aes(x = reorder(row.names(energyact_fin_ordered_env), -max_similarity_env), y = max_similarity_env)) +
  geom_hline(yintercept = median_similarity_env, linetype = "dashed", color = "blue") +
  geom_point() +
  # theme(axis.text.x = element_blank()) +  # Optionally hide x-axis text for legibility
  labs(x = "Words", y = "Max Similarity to Environmental Protection", title = "Similarity Scores for Environmental Protection Category") +
  scale_y_continuous(breaks = seq(0, 1, by = 0.05)) +  # Set y-axis breaks
  theme_classic()

plot_sim_env
#threshold ~0.82
```


```{r}
# Pivoting into longer format
energyact_fin_long <- energyact_fin %>%
  pivot_longer(cols = c(max_similarity_econ, max_similarity_env),
               names_to = "category",
               values_to = "similarity")

# Median for intendedVote = 0 and 1
medians_by_vote <- energyact_fin_long %>%
  group_by(category, intendedVote) %>%
  summarize(median_similarity = median(similarity, na.rm = TRUE)) %>%
  ungroup()

# Plot 1
plot1 <- ggplot(energyact_fin_long, aes(x = reorder(word, -similarity), y = similarity, color = category)) +
  geom_point() +
  geom_hline(data = medians_by_vote, aes(yintercept = median_similarity, color = category), linetype = "dashed") +
  scale_color_manual(values = c("max_similarity_econ" = "blue", "max_similarity_env" = "green")) +
  facet_wrap(~ intendedVote) +
  theme_minimal() +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) +
  labs(x = "Words", y = "Max Similarity Score", title = "Distribution of Similarity Scores by Intended Vote") +
  scale_y_continuous(breaks = seq(0, 1, by = 0.05))

print(plot1)
```
```{r}
# Median for each wave
medians_by_wave <- energyact_fin_long %>%
  group_by(category, wave) %>%
  summarize(median_similarity = median(similarity, na.rm = TRUE)) %>%
  ungroup()

# Plot 2
plot2 <- ggplot(energyact_fin_long, aes(x = reorder(word, -similarity), y = similarity, color = category)) +
  geom_point() +
  geom_hline(data = medians_by_wave, aes(yintercept = median_similarity, color = category), linetype = "dashed") +
  scale_color_manual(values = c("max_similarity_econ" = "blue", "max_similarity_env" = "green")) +
  facet_grid(wave ~ intendedVote) +
  theme_minimal() +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) +
  labs(x = "Words", y = "Max Similarity Score", title = "Distribution of Similarity Scores by Intended Vote and Wave") +
  scale_y_continuous(breaks = seq(0, 1, by = 0.05))

print(plot2)
```
```{r}
# Separate plots for each category
plot3_econ <- ggplot(subset(energyact_fin_long, category == "max_similarity_econ"), aes(x = reorder(word, -similarity), y = similarity)) +
  geom_point(color = "blue") +
  geom_hline(data = subset(medians_by_vote, category == "max_similarity_econ"), aes(yintercept = median_similarity), linetype = "dashed", color = "blue") +
  facet_wrap(~ intendedVote) +
  theme_minimal() +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) +
  labs(x = "Words", y = "Max Similarity Score (Economic)", title = "Economic Similarity Scores by Intended Vote") +
  scale_y_continuous(breaks = seq(0, 1, by = 0.05))

plot3_env <- ggplot(subset(energyact_fin_long, category == "max_similarity_env"), aes(x = reorder(word, -similarity), y = similarity)) +
  geom_point(color = "green") +
  geom_hline(data = subset(medians_by_vote, category == "max_similarity_env"), aes(yintercept = median_similarity), linetype = "dashed", color = "green") +
  facet_wrap(~ intendedVote) +
  theme_minimal() +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) +
  labs(x = "Words", y = "Max Similarity Score (Environmental)", title = "Environmental Similarity Scores by Intended Vote") +
  scale_y_continuous(breaks = seq(0, 1, by = 0.05))

print(plot3_econ)
print(plot3_env)
```



```{r}
#Export plots
# Export plot_sim_econ
ggsave("similarity_distribution_wave_vote.png", plot = plot2, width = 10, height = 8, dpi = 300)

# Export plot_sim_env
ggsave("similarity_econ_vote.png", plot = plot3_econ, width = 10, height = 8, dpi = 300)

# Export plot_H1_median
ggsave("similarity_env_vote.png", plot = plot3_env, width = 10, height = 8, dpi = 300)
```

```{r}
#Factorize intended Vote
energyact_fin$fintendedVote <- factor(energyact_fin$intendedVote, levels = c(0, 1))

# Logistic regression model with random intercepts for participantID
model_H1 <- glmer(fintendedVote ~ max_similarity_econ + max_similarity_env + (1 | participantID), 
               data = energyact_fin, 
               family = binomial)

summary(model_H1)

# Calculate odds ratios
odds_ratios_H1 <- exp(coef(summary(model_H1)))

# The exponentiated coefficients are the odds ratios for the fixed effects
odds_ratios_H1
```

```{r}
# Subset the data for wave t1 and t2
data_t1 <- subset(energyact_fin, wave == "t1")
data_t2 <- subset(energyact_fin, wave == "t2")

# Logistic regression model for wave t1
model_t1 <- glmer(intendedVote ~ max_similarity_econ + max_similarity_env + (1 | participantID), 
                  data = data_t1, 
                  family = binomial)

# Logistic regression model for wave t2
model_t2 <- glmer(intendedVote ~ max_similarity_econ + max_similarity_env + (1 | participantID), 
                  data = data_t2, 
                  family = binomial)

# Summarize the models
summary(model_t1)
summary(model_t2)

# Calculate odds ratios for wave t1
odds_ratios_t1 <- exp(coef(summary(model_t1)))

# Calculate odds ratios for wave t2
odds_ratios_t2 <- exp(coef(summary(model_t2)))

# Display odds ratios
odds_ratios_t1
odds_ratios_t2
```
