---
title: "H1_energyact emb2"
output:
  pdf_document: default
  html_document: default
date: "Sys.Date()"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#Install and load necessary packages
packages <- c("devtools","here","dplyr","tidyverse","readxl","writexl","hunspell","text2vec","car","broom","lme4","Matrix")
for (package in packages) {
  if (!requireNamespace(package, quietly = TRUE)) {
    install.packages(package)
  }
}
lapply(packages,library, character.only=T)
```

```{r}
#Install and load embedR
if (!requireNamespace("embedR", quietly = TRUE)) {
    # If not installed, install it using devtools
    devtools::install_github("dwulff/embedR")
}

library("embedR")
```

```{r}
#read in final dataset
energyact_fin <- read_xlsx(here::here("data","energyact_final.xlsx"))

#read in matching dataset
matchids <- read.csv(here::here("data","Match_participantID.csv"),sep = ";")
matchids2 <- matchids %>% select(participantID.wave1,participantID.wave2)

# Select unique rows
matchids2 <- unique(matchids2)

#load embeddings as R object
embedding <- readRDS(here::here("data","embedding.rds"))
```

```{r,eval=F, echo=F}
#embed chatGPT list
#economy words
#embedR::er_set_tokens("cohere" = "x","huggingface"="x","openai" = "x")

#embedding_econ = er_embed(c("kosten","teuer","preis","arbeit","investition","wirtschaft","finanzierung","budget","ausgaben","steuern","subvention","gewinn","verlust","rendite","sparen","wettbewerb","verschuldung","einkommen","umsatz","markt"),api="cohere",model="embed-multilingual-v3.0")

#environmental prot words
#embedding_env = er_embed(c("umweltschutz","klimaschutz","dringend","notwendig","nachhaltigkeit","erneuerbar","ökologie","biodiversität","artenschutz","ressourcenschonung","emission","klimawandel","ökosystem","umweltbewusstsein","grüne energie","verschmutzung","zeitdruck","landschaftsschutz","naturschutz","tierschutz"),api="cohere",model="embed-multilingual-v3.0")
```

```{r,eval=F, echo=F}
#save embeddings as R object
#saveRDS(embedding_econ, here::here("data","embedding_econ.rds"))

#saveRDS(embedding_env, here::here("data","embedding_env.rds"))

```

```{r}
#Remove t1 and t2 from ID
energyact_fin <- energyact_fin %>%
  mutate(participantID = gsub("_t[1|2]$", "", participantID))
```

```{r}
# 2. Merge energyact_fin with matchids2 based on participantID of wave 1
# This will add the participantID.wave2 column to your energyact_fin dataframe for matching rows
energyact_fin <- energyact_fin %>%
  left_join(matchids2, by = c("participantID" = "participantID.wave1"))

# 3. Update the participantID for wave 1 participants with their corresponding wave 2 IDs
energyact_fin <- energyact_fin %>%
  mutate(participantID = if_else(wave == "t1" & !is.na(participantID.wave2), participantID.wave2, participantID))

# 4. Optionally, remove the temporary columns added during the merge
energyact_fin$participantID.wave1 <- NULL
energyact_fin$participantID.wave2 <- NULL

# Count the unique participantIDs in the dataframe
number_of_unique_ids <- energyact_fin %>% 
  summarise(unique_ids = n_distinct(participantID)) %>%
  pull(unique_ids)

# Print the number of unique participantIDs
print(number_of_unique_ids)
```

```{r}
set.seed(26)

calculate_max_similarity <- function(embedding_study, embedding_list) {
  # Calculate cosine similarity
  similarity_matrix <- sim2(embedding_study, embedding_list, method = "cosine")
  # Get the maximum similarity score for each word
  max_similarity <- apply(similarity_matrix, 1, max)
  return(max_similarity)
}
```

```{r}
#Load embeddings
embedding_econ <- readRDS(here::here("data","embedding_econ.rds"))

embedding_env <- readRDS(here::here("data","embedding_env.rds"))
# Creating a dataframe from the study embedding matrix
H1_df <- as.data.frame(embedding)

# Save the rownames as the first column in H1_df
H1_df$word <- rownames(H1_df)

# Reset the rownames of H1_df
rownames(H1_df) <- NULL



# Calculate max similarities
H1_df$max_similarity_econ <- calculate_max_similarity(embedding, embedding_econ)
H1_df$max_similarity_env <- calculate_max_similarity(embedding, embedding_env)
```

```{r}
#add similarity columns to energyact_fin
# Get the names of the last two columns
last_two_columns <- names(H1_df)[(ncol(H1_df)-1):ncol(H1_df)]

# Add the last two columns from H1_df to energyact_fin
energyact_fin[last_two_columns] <- H1_df[last_two_columns]
```

```{r}
# Assuming your original dataframe is named energyact_fin
# First, identify participants present in both waves
participants_in_both_waves <- energyact_fin %>%
  group_by(participantID) %>%
  filter(all(c("t1", "t2") %in% wave)) %>%
  ungroup() %>%
  select(participantID) %>%
  distinct()

# Now, filter the original dataframe to include only those participants
energyact_fin_both <- energyact_fin %>%
  semi_join(participants_in_both_waves, by = "participantID")

# Check the structure of the new dataframe
str(energyact_fin_both)
```

```{r}
#Visualize similarity distribution
#First create ordered df
energyact_fin_ordered_econ <- energyact_fin[order(-energyact_fin$max_similarity_econ), ]

#Calculate median similarity
median_similarity_econ <- median(energyact_fin_ordered_econ$max_similarity_econ, na.rm = TRUE)

# Create the plot
similarity_econ <- ggplot(energyact_fin_ordered_econ, aes(x = reorder(row.names(energyact_fin_ordered_econ), -max_similarity_econ), y = max_similarity_econ)) +
  geom_hline(yintercept = median_similarity_econ, linetype = "dashed", color = "blue") +
  geom_point() +
  #theme(axis.text.x = element_blank()) +  # Hide x-axis text for legibility
  labs(x = "Words", y = "Max Similarity to Economy", title = "Similarity Scores for Economy Category") +
  scale_y_continuous(breaks = seq(0, 1, by = 0.05)) +  # Set y-axis breaks
  theme_classic()

ggsave(here::here("plot","similarity_dis","similarity_dis","similarity_econ.png"), similarity_econ, width = 10, height = 8, dpi = 300,bg="transparent")
```

```{r}
# Create ordered dataframe based on max_similarity_env
energyact_fin_ordered_env <- energyact_fin[order(-energyact_fin$max_similarity_env), ]

# Calculate median similarity for environmental protection
median_similarity_env <- median(energyact_fin_ordered_env$max_similarity_env, na.rm = TRUE)

# Create the plot for environmental protection similarity
similarity_env <- ggplot(energyact_fin_ordered_env, aes(x = reorder(row.names(energyact_fin_ordered_env), -max_similarity_env), y = max_similarity_env)) +
  geom_hline(yintercept = median_similarity_env, linetype = "dashed", color = "blue") +
  geom_point() +
  # theme(axis.text.x = element_blank()) +  # Optionally hide x-axis text for legibility
  labs(x = "Words", y = "Max Similarity to Environmental Protection", title = "Similarity Scores for Environmental Protection Category") +
  scale_y_continuous(breaks = seq(0, 1, by = 0.05)) +  # Set y-axis breaks
  theme_classic()

ggsave(here::here("plot","similarity_dis","similarity_dis","similarity_env.png"), similarity_env, width = 10, height = 8, dpi = 300,bg="transparent")
```


```{r}
# Pivoting into longer format
energyact_fin_long <- energyact_fin %>%
  pivot_longer(cols = c(max_similarity_econ, max_similarity_env),
               names_to = "category",
               values_to = "similarity")

# Median for intendedVote = 0 and 1
medians_by_vote <- energyact_fin_long %>%
  group_by(category, intendedVote) %>%
  summarize(median_similarity = median(similarity, na.rm = TRUE)) %>%
  ungroup()

# Plot 1
similarity_H1_vote <- ggplot(energyact_fin_long, aes(x = reorder(word, -similarity), y = similarity, color = category)) +
  geom_point() +
  geom_hline(data = medians_by_vote, aes(yintercept = median_similarity, color = category), linetype = "dashed") +
  scale_color_manual(values = c("max_similarity_econ" = "blue", "max_similarity_env" = "green")) +
  facet_wrap(~ intendedVote) +
  theme_minimal() +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) +
  labs(x = "Words", y = "Max Similarity Score", title = "Distribution of Similarity Scores by Intended Vote") +
  scale_y_continuous(breaks = seq(0, 1, by = 0.05))

ggsave(here::here("plot","similarity_dis","similarity_H1_vote.png"), similarity_H1_vote, width = 10, height = 8, dpi = 300,bg="transparent")
```

```{r}
# Median for each wave
medians_by_wave <- energyact_fin_long %>%
  group_by(category, wave) %>%
  summarize(median_similarity = median(similarity, na.rm = TRUE)) %>%
  ungroup()

# Plot 2
similarity_H1_vote_wave <- ggplot(energyact_fin_long, aes(x = reorder(word, -similarity), y = similarity, color = category)) +
  geom_point() +
  geom_hline(data = medians_by_wave, aes(yintercept = median_similarity, color = category), linetype = "dashed") +
  scale_color_manual(values = c("max_similarity_econ" = "blue", "max_similarity_env" = "green")) +
  facet_grid(wave ~ intendedVote) +
  theme_minimal() +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) +
  labs(x = "Words", y = "Max Similarity Score", title = "Distribution of Similarity Scores by Intended Vote and Wave") +
  scale_y_continuous(breaks = seq(0, 1, by = 0.05))

ggsave(here::here("plot","similarity_dis","similarity_H1_vote_wave.png"), similarity_H1_vote_wave, width = 10, height = 8, dpi = 300,bg="transparent")
```

```{r}
# Separate plots for each category
similarity_econ_vote <- ggplot(subset(energyact_fin_long, category == "max_similarity_econ"), aes(x = reorder(word, -similarity), y = similarity)) +
  geom_point(color = "blue") +
  geom_hline(data = subset(medians_by_vote, category == "max_similarity_econ"), aes(yintercept = median_similarity), linetype = "dashed", color = "blue") +
  facet_wrap(~ intendedVote) +
  theme_minimal() +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) +
  labs(x = "Words", y = "Max Similarity Score (Economic)", title = "Economic Similarity Scores by Intended Vote") +
  scale_y_continuous(breaks = seq(0, 1, by = 0.05))

ggsave(here::here("plot","similarity_dis","similarity_econ_vote.png"), similarity_econ_vote, width = 10, height = 8, dpi = 300,bg="transparent")

similarity_env_vote <- ggplot(subset(energyact_fin_long, category == "max_similarity_env"), aes(x = reorder(word, -similarity), y = similarity)) +
  geom_point(color = "green") +
  geom_hline(data = subset(medians_by_vote, category == "max_similarity_env"), aes(yintercept = median_similarity), linetype = "dashed", color = "green") +
  facet_wrap(~ intendedVote) +
  theme_minimal() +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) +
  labs(x = "Words", y = "Max Similarity Score (Environmental)", title = "Environmental Similarity Scores by Intended Vote") +
  scale_y_continuous(breaks = seq(0, 1, by = 0.05))

ggsave(here::here("plot","similarity_dis","similarity_env_vote.png"), similarity_env_vote, width = 10, height = 8, dpi = 300,bg="transparent")

```


```{r}
#Factorize intended Vote
energyact_fin_both$fintendedVote <- factor(energyact_fin_both$intendedVote, levels = c(0, 1))

# Ensure 'wave' is treated as a factor if you plan to use it directly or interact it with other predictors
energyact_fin_both$fwave <- factor(energyact_fin_both$wave, levels = c("t1", "t2"))

# Model with random intercepts for participantID to account for between-participant variability
# This model does not include 'wave' as a fixed effect since the main predictors are 'max_similarity_econ' and 'max_similarity_env'
# However, it acknowledges within-participant variability through the random intercepts
model_H1 <- glmer(fintendedVote ~ max_similarity_econ + max_similarity_env + (1 | participantID), 
                  data = energyact_fin_both, 
                  family = binomial)

summary(model_H1)
```

```{r}
# Model with random intercepts for participantID and by considering wave as a within-subjects factor
# This model includes wave as a fixed effect to see its overall effect and allows for random intercepts across participants
model_H1_with_wave <- glmer(fintendedVote ~ max_similarity_econ + max_similarity_env + fwave + (1 | participantID), 
                            data = energyact_fin_both, 
                            family = binomial)

summary(model_H1_with_wave)
```

```{r}
#Check Assumptions
# Calculate Pearson residuals
residuals_pearson <- residuals(model_H1_with_wave, type = "pearson")

# Plotting the Pearson residuals against fitted values
plot(fitted(model_H1_with_wave), residuals_pearson,
     xlab = "Fitted Values", ylab = "Pearson Residuals",
     main = "Residuals vs Fitted")
abline(h = 0, col = "red")

# Extract random effects
ran_eff <- ranef(model_H1_with_wave)$participantID

# Plotting a histogram of random intercepts
hist(ran_eff[, "(Intercept)"], breaks = 20, main = "Histogram of Random Intercepts")

# QQ plot of random intercepts
qqnorm(ran_eff[, "(Intercept)"])
qqline(ran_eff[, "(Intercept)"], col = "red")

```


```{r}
# Extract random intercepts for participantID
random_intercepts <- ranef(model_H1_with_wave)$participantID[, "(Intercept)"]

# Plot a histogram of the random intercepts
hist(random_intercepts, breaks = 30, main = "Histogram of Random Intercepts", xlab = "Random Intercept Values")

# QQ plot for random intercepts
qqnorm(random_intercepts)
qqline(random_intercepts, col = "red")

# Shapiro-Wilk test for normality
shapiro.test(random_intercepts)
```

```{r}
# Fit a simplified glm model with the same fixed effects for demonstration
simplified_model <- glm(fintendedVote ~ max_similarity_econ + max_similarity_env + wave,
                        family = binomial, data = energyact_fin_both)

# Calculate VIF for the fixed effects predictors in the simplified model
vif_values <- vif(simplified_model)

# Print the VIF values
print(vif_values)
```

